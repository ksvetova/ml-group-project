{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8078b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8354ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and modify data\n",
    "npf_train = pd.read_csv(\"npf_train.csv\")\n",
    "npf_train = npf_train.drop(\"partlybad\",axis=1)\n",
    "\n",
    "npf_train = npf_train.set_index(\"date\")\n",
    "## Tell that \"class4\" is categorical variable. (R does this automatically.)\n",
    "npf_train[\"class4\"] = npf_train[\"class4\"].astype(\"category\")\n",
    "\n",
    "## Here date column was converted to index and we do not need to get rid of it.\n",
    "npf_train = npf_train.drop(\"id\",axis=1)\n",
    "\n",
    "## If you don't use dtype=\"object\" array will cut strings...\n",
    "class2 = np.array([\"event\"]*npf_train.shape[0],dtype=\"object\")\n",
    "class2[npf_train[\"class4\"]==\"nonevent\"] = \"nonevent\"\n",
    "npf_train[\"class2\"] = class2\n",
    "npf_train[\"class2\"] = npf_train[\"class2\"].astype(\"category\")\n",
    "\n",
    "\n",
    "# reformating X to numerics\n",
    "for i in range(1,101): # 101 because we have 102 columns\n",
    "    npf_train.iloc[:,i] = pd.to_numeric(list(npf_train.iloc[:,i]))\n",
    "\n",
    "## REDUCING the set to get a training and a test set (360 ~ 80% of 458)\n",
    "X = npf_train.iloc[:360, 1:-1]\n",
    "y = npf_train.iloc[:360, -1]\n",
    "\n",
    "# our test set:\n",
    "X_test = npf_train.iloc[360:, 1:-1]\n",
    "y_test = npf_train.iloc[360:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fffa92c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression model (a basic one for reference)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "t_model_lr = model_lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e6d036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8673469387755102"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing the score\n",
    "score_lr = t_model_lr.score(X_test, y_test)\n",
    "score_lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55cd145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8469387755102041"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain with higher max_iter & computing score\n",
    "model_lr_higher_maxiter = LogisticRegression(max_iter= 10000)\n",
    "t_model_lr_higher_maxiter = model_lr_higher_maxiter.fit(X,y)\n",
    "t_model_lr_higher_maxiter_score = t_model_lr_higher_maxiter.score(X_test, y_test) \n",
    "t_model_lr_higher_maxiter_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51fb1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred_class</th>\n",
       "      <th>y_pred_proba</th>\n",
       "      <th>correct?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CO2168.mean    375.647561\n",
       "CO2168.std       3.2...</td>\n",
       "      <td>event</td>\n",
       "      <td>event</td>\n",
       "      <td>0.925932</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CO2168.mean    382.823235\n",
       "CO2168.std       3.8...</td>\n",
       "      <td>event</td>\n",
       "      <td>event</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO2168.mean    384.067500\n",
       "CO2168.std       2.5...</td>\n",
       "      <td>event</td>\n",
       "      <td>event</td>\n",
       "      <td>0.990653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CO2168.mean    384.472708\n",
       "CO2168.std       1.9...</td>\n",
       "      <td>event</td>\n",
       "      <td>event</td>\n",
       "      <td>0.999330</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CO2168.mean    390.631489\n",
       "CO2168.std       0.8...</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.028212</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>CO2168.mean    377.541538\n",
       "CO2168.std       6.3...</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.280123</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>CO2168.mean    381.016623\n",
       "CO2168.std       4.4...</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CO2168.mean    386.687895\n",
       "CO2168.std      12.0...</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CO2168.mean    379.279128\n",
       "CO2168.std      12.0...</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CO2168.mean    384.443758\n",
       "CO2168.std       6.4...</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>nonevent</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    X    y_true y_pred_class  \\\n",
       "0   CO2168.mean    375.647561\n",
       "CO2168.std       3.2...     event        event   \n",
       "1   CO2168.mean    382.823235\n",
       "CO2168.std       3.8...     event        event   \n",
       "2   CO2168.mean    384.067500\n",
       "CO2168.std       2.5...     event        event   \n",
       "3   CO2168.mean    384.472708\n",
       "CO2168.std       1.9...     event        event   \n",
       "4   CO2168.mean    390.631489\n",
       "CO2168.std       0.8...  nonevent     nonevent   \n",
       "..                                                ...       ...          ...   \n",
       "93  CO2168.mean    377.541538\n",
       "CO2168.std       6.3...  nonevent     nonevent   \n",
       "94  CO2168.mean    381.016623\n",
       "CO2168.std       4.4...  nonevent     nonevent   \n",
       "95  CO2168.mean    386.687895\n",
       "CO2168.std      12.0...  nonevent     nonevent   \n",
       "96  CO2168.mean    379.279128\n",
       "CO2168.std      12.0...  nonevent     nonevent   \n",
       "97  CO2168.mean    384.443758\n",
       "CO2168.std       6.4...  nonevent     nonevent   \n",
       "\n",
       "    y_pred_proba  correct?  \n",
       "0       0.925932      True  \n",
       "1       0.996606      True  \n",
       "2       0.990653      True  \n",
       "3       0.999330      True  \n",
       "4       0.028212      True  \n",
       "..           ...       ...  \n",
       "93      0.280123      True  \n",
       "94      0.000559      True  \n",
       "95      0.005242      True  \n",
       "96      0.006661      True  \n",
       "97      0.001083      True  \n",
       "\n",
       "[98 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a function outputting the results of the model\n",
    "def pred_proba_class(t_model, X_test_data, y_test_data): # t_model is the trained model\n",
    "    df = pd.DataFrame()\n",
    "    df[\"X\"] = [X_test_data.iloc[i, :] for i in range(len(X_test_data))]\n",
    "    df[\"y_true\"] = np.array(y_test_data)\n",
    "    df[\"y_pred_class\"] = t_model.predict(X_test_data)\n",
    "    proba_event= t_model.predict_proba(X_test_data)[:,0]\n",
    "    df[\"y_pred_proba\"] = proba_event\n",
    "    df[\"correct?\"] = [df.iloc[i,1] == df.iloc[i,2] for i in range(len(df))]\n",
    "    \n",
    "    return df\n",
    "\n",
    "pred_proba_class(t_model_lr_higher_maxiter, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6c349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifications</th>\n",
       "      <th>t_models</th>\n",
       "      <th>simple scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RR newton</td>\n",
       "      <td>LogisticRegression(solver='newton-cg')</td>\n",
       "      <td>0.846939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RR sag</td>\n",
       "      <td>LogisticRegression(solver='sag')</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RR saga</td>\n",
       "      <td>LogisticRegression(solver='saga')</td>\n",
       "      <td>0.846939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso saga</td>\n",
       "      <td>LogisticRegression(penalty='l1', solver='saga')</td>\n",
       "      <td>0.846939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none newton</td>\n",
       "      <td>LogisticRegression(penalty='none', solver='new...</td>\n",
       "      <td>0.683673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none sag</td>\n",
       "      <td>LogisticRegression(penalty='none', solver='sag')</td>\n",
       "      <td>0.887755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none saga</td>\n",
       "      <td>LogisticRegression(penalty='none', solver='saga')</td>\n",
       "      <td>0.846939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso+RR saga</td>\n",
       "      <td>LogisticRegression(l1_ratio=0.5, penalty='elas...</td>\n",
       "      <td>0.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modifications                                           t_models  \\\n",
       "0      RR newton             LogisticRegression(solver='newton-cg')   \n",
       "1         RR sag                   LogisticRegression(solver='sag')   \n",
       "2        RR saga                  LogisticRegression(solver='saga')   \n",
       "3     Lasso saga    LogisticRegression(penalty='l1', solver='saga')   \n",
       "4    none newton  LogisticRegression(penalty='none', solver='new...   \n",
       "5       none sag   LogisticRegression(penalty='none', solver='sag')   \n",
       "6      none saga  LogisticRegression(penalty='none', solver='saga')   \n",
       "7  Lasso+RR saga  LogisticRegression(l1_ratio=0.5, penalty='elas...   \n",
       "\n",
       "   simple scores  \n",
       "0       0.846939  \n",
       "1       0.897959  \n",
       "2       0.846939  \n",
       "3       0.846939  \n",
       "4       0.683673  \n",
       "5       0.887755  \n",
       "6       0.846939  \n",
       "7       0.846939  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modifying the logistic regression trying to improve the score:\n",
    "\n",
    "# cross validation for evaluation \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### predictor selection\n",
    "# lbfgs and liblinear are not to be used since we want to be able to extend our model to class4 prediction\n",
    "\n",
    "# Ridge Regression = penalty l2 --> default\n",
    "model_lr_rr_newton = LogisticRegression(penalty = \"l2\", solver = 'newton-cg')\n",
    "t_model_lr_rr_newton = model_lr_rr_newton.fit(X,y)\n",
    "score_lr_rr_newton = t_model_lr_rr_newton.score(X_test, y_test)\n",
    "\n",
    "model_lr_rr_sag = LogisticRegression(penalty = \"l2\", solver = 'sag')\n",
    "t_model_lr_rr_sag = model_lr_rr_sag.fit(X,y)\n",
    "score_lr_rr_sag = t_model_lr_rr_sag.score(X_test, y_test)\n",
    "\n",
    "model_lr_rr_saga = LogisticRegression(penalty = \"l2\", solver = 'saga')\n",
    "t_model_lr_rr_saga = model_lr_rr_saga.fit(X,y)\n",
    "score_lr_rr_saga = t_model_lr_rr_saga.score(X_test, y_test)\n",
    "\n",
    "# Lasso = penalty l1 \n",
    "model_lr_lasso = LogisticRegression(penalty = \"l1\", solver = 'saga')# this solver bc it is the only option for multiclass & l1\n",
    "t_model_lr_lasso = model_lr_lasso.fit(X,y)\n",
    "score_lr_lasso = t_model_lr_lasso.score(X_test, y_test)\n",
    "\n",
    "# none= penalty none\n",
    "model_lr_none_newton = LogisticRegression(penalty = \"none\", solver = 'newton-cg')\n",
    "t_model_lr_none_newton = model_lr_none_newton.fit(X,y)\n",
    "score_lr_none_newton = t_model_lr_none_newton.score(X_test, y_test)\n",
    "\n",
    "model_lr_none_sag = LogisticRegression(penalty = \"none\", solver = 'sag')\n",
    "t_model_lr_none_sag = model_lr_none_sag.fit(X,y)\n",
    "score_lr_none_sag = t_model_lr_none_sag.score(X_test, y_test)\n",
    "\n",
    "model_lr_none_saga = LogisticRegression(penalty = \"none\", solver = 'saga')\n",
    "t_model_lr_none_saga = model_lr_none_saga.fit(X,y)\n",
    "score_lr_none_saga = t_model_lr_none_saga.score(X_test, y_test)\n",
    "\n",
    "# Lasso + Ridge = ??? = penalty elasticnet\n",
    "model_lr_elastic = LogisticRegression(penalty = \"elasticnet\", solver = 'saga', l1_ratio = 0.5) # this solver bc it's the only option, l1_ratio just in the middle for now\n",
    "t_model_lr_elastic = model_lr_elastic.fit(X,y)\n",
    "score_lr_elastic = t_model_lr_elastic.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# parameter tuning\n",
    "\n",
    "\n",
    "\n",
    "# df for modifications, t_mode and score\n",
    "mms = pd.DataFrame()\n",
    "mms[\"modifications\"] = ['RR newton', 'RR sag', 'RR saga', 'Lasso saga', 'none newton', 'none sag', 'none saga', 'Lasso+RR saga']\n",
    "mms[\"t_models\"] = [t_model_lr_rr_newton, t_model_lr_rr_sag, t_model_lr_rr_saga, t_model_lr_lasso, t_model_lr_none_newton, t_model_lr_none_sag, t_model_lr_none_saga, t_model_lr_elastic]\n",
    "mms[\"simple scores\"] = [score_lr_rr_newton, score_lr_rr_sag, score_lr_rr_saga, score_lr_lasso, score_lr_none_newton, score_lr_none_sag, score_lr_none_saga, score_lr_elastic]\n",
    "mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2907f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifications</th>\n",
       "      <th>t_models</th>\n",
       "      <th>simple scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RR newton</td>\n",
       "      <td>LogisticRegression(max_iter=1000, solver='newt...</td>\n",
       "      <td>0.846939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RR sag</td>\n",
       "      <td>LogisticRegression(max_iter=1000, solver='sag')</td>\n",
       "      <td>0.867347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RR saga</td>\n",
       "      <td>LogisticRegression(max_iter=1000, solver='saga')</td>\n",
       "      <td>0.887755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso saga</td>\n",
       "      <td>LogisticRegression(max_iter=1000, penalty='l1'...</td>\n",
       "      <td>0.887755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none newton</td>\n",
       "      <td>LogisticRegression(max_iter=1000, penalty='non...</td>\n",
       "      <td>0.673469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none sag</td>\n",
       "      <td>LogisticRegression(max_iter=1000, penalty='non...</td>\n",
       "      <td>0.867347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none saga</td>\n",
       "      <td>LogisticRegression(max_iter=1000, penalty='non...</td>\n",
       "      <td>0.887755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso+RR saga</td>\n",
       "      <td>LogisticRegression(l1_ratio=0.5, max_iter=1000...</td>\n",
       "      <td>0.887755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modifications                                           t_models  \\\n",
       "0      RR newton  LogisticRegression(max_iter=1000, solver='newt...   \n",
       "1         RR sag    LogisticRegression(max_iter=1000, solver='sag')   \n",
       "2        RR saga   LogisticRegression(max_iter=1000, solver='saga')   \n",
       "3     Lasso saga  LogisticRegression(max_iter=1000, penalty='l1'...   \n",
       "4    none newton  LogisticRegression(max_iter=1000, penalty='non...   \n",
       "5       none sag  LogisticRegression(max_iter=1000, penalty='non...   \n",
       "6      none saga  LogisticRegression(max_iter=1000, penalty='non...   \n",
       "7  Lasso+RR saga  LogisticRegression(l1_ratio=0.5, max_iter=1000...   \n",
       "\n",
       "   simple scores  \n",
       "0       0.846939  \n",
       "1       0.867347  \n",
       "2       0.887755  \n",
       "3       0.887755  \n",
       "4       0.673469  \n",
       "5       0.867347  \n",
       "6       0.887755  \n",
       "7       0.887755  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same thing with maxiter = 1000 --> since there was a worning ...  to see if we get an improvement\n",
    "# tried with max_iter = 1000 and = 10000 (gave warnings but terminated)\n",
    "# --> results with 1000 ha better highest value thus here chosen:\n",
    "\n",
    "# Ridge Regression = penalty l2 --> default\n",
    "model_lr_rr_newton = LogisticRegression(penalty = \"l2\", solver = 'newton-cg', max_iter = 1000)\n",
    "t_model_lr_rr_newton = model_lr_rr_newton.fit(X,y)\n",
    "score_lr_rr_newton = t_model_lr_rr_newton.score(X_test, y_test)\n",
    "\n",
    "model_lr_rr_sag = LogisticRegression(penalty = \"l2\", solver = 'sag',  max_iter = 1000)\n",
    "t_model_lr_rr_sag = model_lr_rr_sag.fit(X,y)\n",
    "score_lr_rr_sag = t_model_lr_rr_sag.score(X_test, y_test)\n",
    "\n",
    "model_lr_rr_saga = LogisticRegression(penalty = \"l2\", solver = 'saga',  max_iter = 1000)\n",
    "t_model_lr_rr_saga = model_lr_rr_saga.fit(X,y)\n",
    "score_lr_rr_saga = t_model_lr_rr_saga.score(X_test, y_test)\n",
    "\n",
    "# Lasso = penalty l1 \n",
    "model_lr_lasso = LogisticRegression(penalty = \"l1\", solver = 'saga',  max_iter = 1000)# this solver bc it is the only option for multiclass & l1\n",
    "t_model_lr_lasso = model_lr_lasso.fit(X,y)\n",
    "score_lr_lasso = t_model_lr_lasso.score(X_test, y_test)\n",
    "\n",
    "# none= penalty none\n",
    "model_lr_none_newton = LogisticRegression(penalty = \"none\", solver = 'newton-cg',  max_iter = 1000)\n",
    "t_model_lr_none_newton = model_lr_none_newton.fit(X,y)\n",
    "score_lr_none_newton = t_model_lr_none_newton.score(X_test, y_test)\n",
    "\n",
    "model_lr_none_sag = LogisticRegression(penalty = \"none\", solver = 'sag',  max_iter = 1000)\n",
    "t_model_lr_none_sag = model_lr_none_sag.fit(X,y)\n",
    "score_lr_none_sag = t_model_lr_none_sag.score(X_test, y_test)\n",
    "\n",
    "model_lr_none_saga = LogisticRegression(penalty = \"none\", solver = 'saga',  max_iter = 1000)\n",
    "t_model_lr_none_saga = model_lr_none_saga.fit(X,y)\n",
    "score_lr_none_saga = t_model_lr_none_saga.score(X_test, y_test)\n",
    "\n",
    "# Lasso + Ridge = ??? = penalty elasticnet\n",
    "model_lr_elastic = LogisticRegression(penalty = \"elasticnet\", solver = 'saga', l1_ratio = 0.5,  max_iter = 1000) # this solver bc it's the only option, l1_ratio just in the middle for now\n",
    "t_model_lr_elastic = model_lr_elastic.fit(X,y)\n",
    "score_lr_elastic = t_model_lr_elastic.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# further parameter tuning possible\n",
    "\n",
    "\n",
    "\n",
    "# df for modifications, t_mode and score\n",
    "mmsMI = pd.DataFrame()\n",
    "mmsMI[\"modifications\"] = ['RR newton', 'RR sag', 'RR saga', 'Lasso saga', 'none newton', 'none sag', 'none saga', 'Lasso+RR saga']\n",
    "mmsMI[\"t_models\"] = [t_model_lr_rr_newton, t_model_lr_rr_sag, t_model_lr_rr_saga, t_model_lr_lasso, t_model_lr_none_newton, t_model_lr_none_sag, t_model_lr_none_saga, t_model_lr_elastic]\n",
    "mmsMI[\"simple scores\"] = [score_lr_rr_newton, score_lr_rr_sag, score_lr_rr_saga, score_lr_lasso, score_lr_none_newton, score_lr_none_sag, score_lr_none_saga, score_lr_elastic]\n",
    "mmsMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c475a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the upper models using cross validation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv10 = []\n",
    "cv50 = []\n",
    "\n",
    "for model in mms[\"t_models\"]:\n",
    "    cv = cross_val_score(model, X,y, cv = 10)\n",
    "    cv10.append(cv)\n",
    "    cv = cross_val_score(model, X,y, cv = 50)\n",
    "    cv50.append(cv)\n",
    "    \n",
    "mms[\"cv score 10 fold\"] = cv10\n",
    "mms[\"cv score 50 fold\"] = cv50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea22841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifications</th>\n",
       "      <th>t_models</th>\n",
       "      <th>simple scores</th>\n",
       "      <th>cv score 10 fold</th>\n",
       "      <th>cv score 50 fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RR newton</td>\n",
       "      <td>LogisticRegression(solver='newton-cg')</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>[0.7777777777777778, 0.8333333333333334, 0.694...</td>\n",
       "      <td>[0.625, 0.75, 0.875, 0.75, 1.0, 0.75, 0.75, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RR sag</td>\n",
       "      <td>LogisticRegression(solver='sag')</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>[0.8888888888888888, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.875, 0.875, 0.75, 1.0, 0.875, 0.75, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RR saga</td>\n",
       "      <td>LogisticRegression(solver='saga')</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>[0.8611111111111112, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso saga</td>\n",
       "      <td>LogisticRegression(penalty='l1', solver='saga')</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>[0.8611111111111112, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none newton</td>\n",
       "      <td>LogisticRegression(penalty='none', solver='new...</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>[0.7777777777777778, 0.8888888888888888, 0.611...</td>\n",
       "      <td>[0.75, 0.75, 0.875, 0.75, 0.875, 0.875, 0.75, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none sag</td>\n",
       "      <td>LogisticRegression(penalty='none', solver='sag')</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>[0.8888888888888888, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.875, 0.875, 0.75, 1.0, 0.875, 0.75, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none saga</td>\n",
       "      <td>LogisticRegression(penalty='none', solver='saga')</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>[0.8611111111111112, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso+RR saga</td>\n",
       "      <td>LogisticRegression(l1_ratio=0.5, penalty='elas...</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>[0.8611111111111112, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modifications                                           t_models  \\\n",
       "0      RR newton             LogisticRegression(solver='newton-cg')   \n",
       "1         RR sag                   LogisticRegression(solver='sag')   \n",
       "2        RR saga                  LogisticRegression(solver='saga')   \n",
       "3     Lasso saga    LogisticRegression(penalty='l1', solver='saga')   \n",
       "4    none newton  LogisticRegression(penalty='none', solver='new...   \n",
       "5       none sag   LogisticRegression(penalty='none', solver='sag')   \n",
       "6      none saga  LogisticRegression(penalty='none', solver='saga')   \n",
       "7  Lasso+RR saga  LogisticRegression(l1_ratio=0.5, penalty='elas...   \n",
       "\n",
       "   simple scores                                   cv score 10 fold  \\\n",
       "0       0.846939  [0.7777777777777778, 0.8333333333333334, 0.694...   \n",
       "1       0.897959  [0.8888888888888888, 0.9166666666666666, 0.722...   \n",
       "2       0.846939  [0.8611111111111112, 0.9166666666666666, 0.722...   \n",
       "3       0.846939  [0.8611111111111112, 0.9166666666666666, 0.722...   \n",
       "4       0.683673  [0.7777777777777778, 0.8888888888888888, 0.611...   \n",
       "5       0.887755  [0.8888888888888888, 0.9166666666666666, 0.722...   \n",
       "6       0.846939  [0.8611111111111112, 0.9166666666666666, 0.722...   \n",
       "7       0.846939  [0.8611111111111112, 0.9166666666666666, 0.722...   \n",
       "\n",
       "                                    cv score 50 fold  \n",
       "0  [0.625, 0.75, 0.875, 0.75, 1.0, 0.75, 0.75, 0....  \n",
       "1  [1.0, 0.875, 0.875, 0.75, 1.0, 0.875, 0.75, 1....  \n",
       "2  [1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...  \n",
       "3  [1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...  \n",
       "4  [0.75, 0.75, 0.875, 0.75, 0.875, 0.875, 0.75, ...  \n",
       "5  [1.0, 0.875, 0.875, 0.75, 1.0, 0.875, 0.75, 1....  \n",
       "6  [1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...  \n",
       "7  [1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b46134a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifications</th>\n",
       "      <th>t_models</th>\n",
       "      <th>simple scores</th>\n",
       "      <th>cv score 10 fold</th>\n",
       "      <th>cv score 50 fold</th>\n",
       "      <th>cv mean score 10</th>\n",
       "      <th>cv mean score 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RR newton</td>\n",
       "      <td>LogisticRegression(solver='newton-cg')</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>[0.7777777777777778, 0.8333333333333334, 0.694...</td>\n",
       "      <td>[0.625, 0.75, 0.875, 0.75, 1.0, 0.75, 0.75, 0....</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.796786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RR sag</td>\n",
       "      <td>LogisticRegression(solver='sag')</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>[0.8888888888888888, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.875, 0.875, 0.75, 1.0, 0.875, 0.75, 1....</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>0.822857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RR saga</td>\n",
       "      <td>LogisticRegression(solver='saga')</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>[0.8611111111111112, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.808929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso saga</td>\n",
       "      <td>LogisticRegression(penalty='l1', solver='saga')</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>[0.8611111111111112, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.808929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none newton</td>\n",
       "      <td>LogisticRegression(penalty='none', solver='new...</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>[0.7777777777777778, 0.8888888888888888, 0.611...</td>\n",
       "      <td>[0.75, 0.75, 0.875, 0.75, 0.875, 0.875, 0.75, ...</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.765357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none sag</td>\n",
       "      <td>LogisticRegression(penalty='none', solver='sag')</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>[0.8888888888888888, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.875, 0.875, 0.75, 1.0, 0.875, 0.75, 1....</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>0.822857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none saga</td>\n",
       "      <td>LogisticRegression(penalty='none', solver='saga')</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>[0.8611111111111112, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.808929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso+RR saga</td>\n",
       "      <td>LogisticRegression(l1_ratio=0.5, penalty='elas...</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>[0.8611111111111112, 0.9166666666666666, 0.722...</td>\n",
       "      <td>[1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.808929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modifications                                           t_models  \\\n",
       "0      RR newton             LogisticRegression(solver='newton-cg')   \n",
       "1         RR sag                   LogisticRegression(solver='sag')   \n",
       "2        RR saga                  LogisticRegression(solver='saga')   \n",
       "3     Lasso saga    LogisticRegression(penalty='l1', solver='saga')   \n",
       "4    none newton  LogisticRegression(penalty='none', solver='new...   \n",
       "5       none sag   LogisticRegression(penalty='none', solver='sag')   \n",
       "6      none saga  LogisticRegression(penalty='none', solver='saga')   \n",
       "7  Lasso+RR saga  LogisticRegression(l1_ratio=0.5, penalty='elas...   \n",
       "\n",
       "   simple scores                                   cv score 10 fold  \\\n",
       "0       0.846939  [0.7777777777777778, 0.8333333333333334, 0.694...   \n",
       "1       0.897959  [0.8888888888888888, 0.9166666666666666, 0.722...   \n",
       "2       0.846939  [0.8611111111111112, 0.9166666666666666, 0.722...   \n",
       "3       0.846939  [0.8611111111111112, 0.9166666666666666, 0.722...   \n",
       "4       0.683673  [0.7777777777777778, 0.8888888888888888, 0.611...   \n",
       "5       0.887755  [0.8888888888888888, 0.9166666666666666, 0.722...   \n",
       "6       0.846939  [0.8611111111111112, 0.9166666666666666, 0.722...   \n",
       "7       0.846939  [0.8611111111111112, 0.9166666666666666, 0.722...   \n",
       "\n",
       "                                    cv score 50 fold  cv mean score 10  \\\n",
       "0  [0.625, 0.75, 0.875, 0.75, 1.0, 0.75, 0.75, 0....          0.800000   \n",
       "1  [1.0, 0.875, 0.875, 0.75, 1.0, 0.875, 0.75, 1....          0.813889   \n",
       "2  [1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...          0.808333   \n",
       "3  [1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...          0.808333   \n",
       "4  [0.75, 0.75, 0.875, 0.75, 0.875, 0.875, 0.75, ...          0.783333   \n",
       "5  [1.0, 0.875, 0.875, 0.75, 1.0, 0.875, 0.75, 1....          0.813889   \n",
       "6  [1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...          0.808333   \n",
       "7  [1.0, 0.75, 0.875, 0.75, 0.875, 1.0, 0.75, 1.0...          0.808333   \n",
       "\n",
       "   cv mean score 50  \n",
       "0          0.796786  \n",
       "1          0.822857  \n",
       "2          0.808929  \n",
       "3          0.808929  \n",
       "4          0.765357  \n",
       "5          0.822857  \n",
       "6          0.808929  \n",
       "7          0.808929  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean cv scores:\n",
    "cvmean_score = []\n",
    "\n",
    "for i in range(len(mms)):\n",
    "    cvmeans = sum(mms.iloc[i,3]) / len(mms.iloc[i,3])\n",
    "    cvmean_score.append(cvmeans)\n",
    "    \n",
    "mms[\"cv mean score 10\"] = cvmean_score\n",
    "\n",
    "\n",
    "cvmean_score = []\n",
    "\n",
    "for i in range(len(mms)):\n",
    "    cvmeans = sum(mms.iloc[i,4]) / len(mms.iloc[i,4])\n",
    "    cvmean_score.append(cvmeans)\n",
    "    \n",
    "mms[\"cv mean score 50\"] = cvmean_score\n",
    "\n",
    "mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> none sag & RR sag with accuracy 81.3/82.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
